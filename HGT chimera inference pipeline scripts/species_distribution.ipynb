{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce26d495-5da8-4c1f-b0d4-89dc011b467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import subprocess\n",
    "import ast\n",
    "import sys\n",
    "sys.path.insert(0, '/n/home11/rkapoor')\n",
    "import tax_pkg\n",
    "from tax_pkg import taxid\n",
    "from tax_pkg import accession2taxid\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b5b47-d974-4aeb-b5f5-e4f9ba162a35",
   "metadata": {},
   "source": [
    "## Consolidate final list of chimeric HGT candidates from manual tree annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b9ff40f-15ed-4d99-a3ac-ba441f1e34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv with manual annotations of  origin for confirmed hgt and metazoan intervals from chimeras\n",
    "metadf=pd.read_csv(\"meta_origin_final.csv\",index_col=0)\n",
    "metas=metadf.index\n",
    "hgtdf=pd.read_csv(\"hgt_origin_final.csv\",index_col=0)\n",
    "hgtdf[\"gene\"]=[x.split(\";\")[1] for x in hgtdf.index]\n",
    "\n",
    "gene_genome={x.split(\";\")[1]:x.split(\";\")[0] for x in hgtdf.index}\n",
    "gene_organism={x:y for x,y in zip(hgtdf.gene,hgtdf.organism)}\n",
    "hgts=hgtdf.index\n",
    "\n",
    "#final set of chimeric hgt genes (both confirmed HGT and metazoan intervals)\n",
    "genes=set([x.split(\";\")[1] for x in  hgts])&set([x.split(\";\")[1] for x in metas])\n",
    "metas_2=[x for x in metas if x.split(\";\")[1] in genes]\n",
    "hgts_2=[x for x in hgts if x.split(\";\")[1] in genes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b41469-08af-4715-adcc-a521bb3596d9",
   "metadata": {},
   "source": [
    "## Make a dataframe storing data (accession, description, taxonomic distribution) for each chimera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af6ff8a-61ee-4235-a74d-27e5534e6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct=\"/n/holyscratch01/extavour_lab/Lab/rkapoor/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d80fcdd-ab74-42d4-ab8e-9b2b653a04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add source genome and organism \n",
    "df_prot=pd.DataFrame(index=list(set(genes)))\n",
    "df_prot.loc[:,\"genome\"]=[gene_genome[x] for x in df_prot.index]\n",
    "df_prot.loc[:,\"organism\"]=[gene_organism[x] for x in df_prot.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef221097-8695-4dfd-9634-e58cddd5d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add protein description \n",
    "for genome in set(df_prot.genome):\n",
    "    file_path=f\"/n/holyscratch01/extavour_lab/Lab/rkapoor/ncbi_dataset/data/{genome}/genomic.gff\"\n",
    "    column_names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']\n",
    "    dfg = pd.read_csv(file_path, sep='\\t', comment='#', names=column_names)\n",
    "    for index, row in df_prot[df_prot.genome==genome].iterrows():\n",
    "        try:\n",
    "            dfi=dfg[dfg.attributes.str.contains(index)]\n",
    "            df_prot.loc[index,\"description\"]=list(dfi.attributes)[0].split(\";product=\")[1].split(\";\")[0]\n",
    "        except:\n",
    "            print(genome,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4fe665c-55a3-467c-b2de-63f395aecfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add information on the taxonomic range of all secondary chimeras to the dataframe\n",
    "secmap={}\n",
    "speciesmap={}\n",
    "for prot in df_prot.index:\n",
    "    td=list(set([x for x in hgts_2 if prot in x])|set([x for x in metas_2 if prot in x]))\n",
    "    target_set=[]\n",
    "    species_set=[]\n",
    "    for t in td:\n",
    "        dft=pd.read_csv(f\"/n/holylabs/LABS/extavour_lab/Users/rkapoor/hmmer_phylo_data/{t}/secondary_chimera.tsv\",sep=\"\\t\")\n",
    "        target_set.append(set(dft.target_name))\n",
    "        species_set.append(set(dft.species))\n",
    "    \n",
    "    dft=pd.read_csv(f\"/n/holylabs/LABS/extavour_lab/Users/rkapoor/hmmer_phylo_data/{t}/phylo_tax2.tsv\",sep=\"\\t\")\n",
    "    target_set = set.intersection(*target_set)\n",
    "    species_set = set.intersection(*species_set)\n",
    "    df_prot.loc[prot,\"taxid_set\"]=str(set(dft[dft.target_name.isin(target_set)].taxid))\n",
    "    df_prot.loc[prot,\"species_set\"]=str(species_set)\n",
    "    df_prot.loc[prot,\"n_species\"]=len(species_set)\n",
    "    df_prot.loc[prot,\"phylum_dist\"]=str(dict(Counter(dft[dft.target_name.isin(target_set)].phylum)))\n",
    "    df_prot.loc[prot,\"order_dist\"]=str(dict(Counter(dft[dft.target_name.isin(target_set)].order)))\n",
    "    secmap[prot]=set(dft.target_name)\n",
    "    speciesmap[prot]=set(dft.species)\n",
    "    \n",
    "for prot in df_prot.index:\n",
    "    classes=[]\n",
    "    for tid in ast.literal_eval(df_prot.loc[prot,\"taxid_set\"]):\n",
    "        l=taxid.get_lineage(tid,{})\n",
    "        classes.append(taxid.get_class(tid,l))\n",
    "    df_prot.loc[prot,\"class_dist\"]=str(dict(Counter(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d8004-dc80-4a7f-a18d-b543f0479c47",
   "metadata": {},
   "source": [
    "## Determine the taxonomic span of each HGT-chimera\n",
    "Tax span is the lowest NCBI taxonomic rank encompassing all primary and secondary chimeras for a given HGT-chimera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6785ce-e3ed-44b7-9450-385258708135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ncbi taxonomy datatabase \n",
    "df_tax=pd.read_csv(\"/n/holyscratch01/extavour_lab/Lab/rkapoor/dbs/names.dmp\",sep=\"\\t\",header=None,index_col=0)\n",
    "#ordered list of ncbi taxonomic ranks (highest to smallest)\n",
    "tax_ranks=['superkingdom', 'kingdom', 'subkingdom', 'superphylum', 'phylum', 'subphylum', 'infraphylum', 'superclass', 'class', 'subclass', 'infraclass', 'cohort', 'subcohort', 'superorder', 'order', 'suborder', 'infraorder', 'parvorder', 'superfamily', 'family', 'subfamily', 'tribe', 'subtribe', 'genus', 'subgenus', 'section', 'subsection', 'series', 'subseries', 'species group', 'species subgroup', 'species', 'forma specialis', 'subspecies', 'varietas', 'subvariety', 'forma', 'serogroup', 'serotype', 'strain', 'isolate']\n",
    "for prot in df_prot.index:\n",
    "    # for every protein, determine the lowest taxonomic rank encompassing all chimeras\n",
    "    lineages=[]\n",
    "    for tid in ast.literal_eval(df_prot.loc[prot,\"taxid_set\"]):\n",
    "        lineages.append(taxid.get_lineage(tid,{}))\n",
    "    keys=[set(x.keys()) for x in lineages]\n",
    "    keys=set.intersection(*keys)-set(\"no rank\")\n",
    "    keys=[x for x in tax_ranks if x in keys][::-1]\n",
    "    for k in keys:\n",
    "        tax_vals=set([str(l[k]) for l in lineages])\n",
    "\n",
    "        if len(set(tax_vals))==1:\n",
    "            df_prot.loc[prot,\"tax_span\"]=list(set(tax_vals))[0]\n",
    "            df_prot.loc[prot,\"tax_span_rank\"]=k\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de368afc-cac0-43d5-b438-32fb7773f73c",
   "metadata": {},
   "source": [
    "## Cluster HGT-Chimeras into orthologous groups using a network approach\n",
    "Network is constructed such that edges connect any two HGT-chimeras related such that at least one is a secondary chimera of the other. Orthologous clusters likely reflecting a single origin are defiend as weakly connected components in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "444136e7-a52e-4c9c-b84a-e9325457724b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Define the directed adjacency list\n",
    "adjacency_list = secmap\n",
    "\n",
    "# Create a directed graph from the adjacency list\n",
    "graph = nx.DiGraph(adjacency_list)\n",
    "\n",
    "# Find connected components\n",
    "components = nx.weakly_connected_components(graph)\n",
    "weak=[]\n",
    "# Print the connected components\n",
    "for component in components:\n",
    "    weak.append(component)\n",
    "\n",
    "components = nx.strongly_connected_components(graph)\n",
    "strong=[]\n",
    "# Print the connected components\n",
    "for component in components:\n",
    "    strong.append(component)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65d2a258-0812-4958-a210-bfd38c94ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert weak cluster identifiers into protein dataframe \n",
    "map1={x:y for x,y in zip(list(range(len(weak))),weak)}\n",
    "map2={}\n",
    "for x in map1:\n",
    "    for y in map1[x]:\n",
    "        map2[y]=x\n",
    "for index, row in df_prot.iterrows():\n",
    "    df_prot.loc[index,\"weak_cc\"]=map2[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791333b6-0b3e-4c48-8998-3b85813041cc",
   "metadata": {},
   "source": [
    "## Make a dataframe for each orthologous cluster, with taxonomic information merged for all constituent chimeras within the cluster\n",
    "Note that clustering was observed to not alter the total taxonomic span/rank of each HGT-chimera, so this information is simply copied from the protein df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2baa7a6-18fc-4949-87f9-7e8c4beaaa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster=pd.DataFrame(index=list(set(df_prot.weak_cc)),columns=[\"proteins\"]+list(df_prot.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0d56dc2-e909-4482-9c3f-de4e24fe9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_cc_counts=dict(Counter(df_prot.weak_cc))\n",
    "multiple_ccs=[x for x in weak_cc_counts if weak_cc_counts[x]>1]\n",
    "for x in weak_cc_counts:\n",
    "    df_cluster.loc[x,\"proteins\"]=str(list(df_prot[df_prot.weak_cc==x].index))\n",
    "    if weak_cc_counts[x]==1:\n",
    "        \n",
    "        df_cluster.loc[x,list(df_prot.columns)]=list(df_prot[df_prot.weak_cc==x].iloc[0,:])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        df_cluster.loc[x,list(df_prot.columns)]=list(df_prot[df_prot.weak_cc==x].iloc[0,:])\n",
    "       \n",
    "        species_sets=[ast.literal_eval(df_prot.loc[xi,\"species_set\"]) for xi in df_prot[df_prot.weak_cc==x].index]\n",
    "        \n",
    "        species_sets=set.union(*species_sets)\n",
    "        df_cluster.loc[x,\"n_species\"]=len(species_sets)\n",
    "        df_cluster.loc[x,\"species_set\"]=str(species_sets)\n",
    "        taxid_sets=[ast.literal_eval(df_prot.loc[xi,\"taxid_set\"]) for xi in df_prot[df_prot.weak_cc==x].index]\n",
    "        taxid_sets=set.union(*taxid_sets)\n",
    "        \n",
    "        \n",
    "        sec_sets=[ast.literal_eval(df_prot.loc[xi,\"secondary_chimeras\"]) for xi in df_prot[df_prot.weak_cc==x].index]\n",
    "        sec_sets=set.union(*sec_sets)\n",
    "        df_cluster.loc[x,\"secondary_chimeras\"]=str(sec_sets)\n",
    "df_cluster.to_csv(\"cluster_info.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a369e-c3a5-4dae-927a-af5449cf9c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rishabh]",
   "language": "python",
   "name": "conda-env-.conda-rishabh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
